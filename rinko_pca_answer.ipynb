{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implement PCA\n",
    "- Use PCA to iris dataset\n",
    "- Introduce PCA by scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Let's implement PCA !\n",
    "HOW TO DO IT?\n",
    "1. Calculate covariance matrix（共分散行列を求める）\n",
    "1. Solve the eigenvalue problem（固有値問題を解く）\n",
    "1. Sort the eigenvalues and eigenvectors in descending order of the eigenvalues（固有値の大きい順に固有値と固有ベクトルをソートする）\n",
    "1. Reduce dimensionality（次元削減する）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Calculate covariance matrix\n",
    "Input : \n",
    "- Input data : $\\boldsymbol{X}=(\\boldsymbol{x_1},\\boldsymbol{x_2},\\cdots,\\boldsymbol{x_N})^\\top\\in\\mathbb{R}^{N\\times K}$ ( $N$ : number of data, $K$ : dimension of each data )\n",
    "\n",
    "Output :\n",
    "1. Average deviation matrix (平均偏差行列) : $\\boldsymbol{\\tilde{X}}=\\boldsymbol{X} - \\boldsymbol{I_N}\\boldsymbol{\\overline{x}}^\\top\\in\\mathbb{R}^{N\\times K}\n",
    "\\quad\\left(\\boldsymbol{\\overline{x}} = \\frac{1}{N}\\sum_n\\boldsymbol{x_n}= \\frac{1}{N}\\boldsymbol{X}^\\top \\boldsymbol{I_N}\\right)$\n",
    "1. Convariance matrix (共分散行列) : $\\boldsymbol{M} = \\frac{1}{N}\\boldsymbol{\\tilde{X}}^\\top \\boldsymbol{\\tilde{X}}\\in\\mathbb{R}^{K\\times K}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Hints</summary>\n",
    "    <div>\n",
    "        <br>\n",
    "        - np.mean(X, axis=None) :  Calculates average of vector or matrix. axis along which the means are computed. The default is to compute the mean of the flattened array. (axisで指定した方向に平均をとる．デフォルトでは全ての要素の平均値．)\n",
    "        <br>\n",
    "        - np.dot(X, Y) : Calculates matrix product (行列積) $\\boldsymbol{X}\\times\\boldsymbol{Y}$\n",
    "        <br>\n",
    "        - X.shape : Returns the shape of input array. ex. $\\boldsymbol{\\tilde{X}}.shape = np.array([N, K])$\n",
    "        <br>\n",
    "        - X.T or X.transpose() : Returns transposed X.\n",
    "        <br>\n",
    "    </div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_converiance_matrix(X):\n",
    "    ### TODO ###\n",
    "    X_bar = X - np.mean(X, axis=0) \n",
    "    M = np.dot(X_bar.T, X_bar) / X.shape[0]\n",
    "    ### TODO ###\n",
    "    return X_bar, M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "Please continue to debug until no error occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 1\n",
    "X = np.arange(16).reshape(4, 4)\n",
    "X_bar, M = calc_converiance_matrix(X)\n",
    "assert (X_bar == np.array([[-6, -2, 2, 6]]* 4).transpose()).all()\n",
    "assert (M == np.cov(X, rowvar=False, bias=1)).all()\n",
    "\n",
    "# test 2\n",
    "X = np.array([[1, 3], [4, 2], [3, 5]])\n",
    "X_bar, M = calc_converiance_matrix(X)\n",
    "assert np.sum((X_bar - np.array([[-5./3, -1./3], [4./3, -4./3], [1./3, 5./3]]))**2) < 1e-8\n",
    "assert np.sum((M - np.cov(X, rowvar=False, bias=1))**2) < 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Solve the eigenvalue problem（固有値問題を解く）\n",
    "Input : \n",
    "- Convariance matrix (共分散行列) : $\\boldsymbol{M} \\in\\mathbb{R}^{K\\times K}$\n",
    "\n",
    "Output : \n",
    "1. Eigenvalues ( $K$個の固有値 ) : $\\boldsymbol{w}\\in\\mathbb{R}^{K}$\n",
    "1. Eigenvectors ( $K$個の固有値ベクトル ) : $\\boldsymbol{V}\\in\\mathbb{R}^{K\\times K}$\n",
    "     - First axis represents NUMBER of DATA. \n",
    "     - Second axis represents DIMENSION of VECTOR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>  \n",
    "    <summary>Hints</summary>\n",
    "    <div>\n",
    "        - np.linalg.eig(X) : Returns eigenvalues (固有値) and eigenvectors (固有ベクトル).\n",
    "        <br>\n",
    "        - eigenvalues : $\\boldsymbol{w}\\in\\mathbb{R}^{K}$  ( $K$ represents number of data.)\n",
    "        <br>\n",
    "        - eigenvectors : $\\boldsymbol{V}\\in\\mathbb{R}^{K\\times K}$ ( First axis represents DIMENSION of VECTOR, second axis represents NUMBER of DATA. )\n",
    "        <br>\n",
    "        - X.T or X.transpose() : Returns transposed X.\n",
    "    </div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_eigen_prob(M):\n",
    "    ### TODO ###\n",
    "    w, V = np.linalg.eig(M)\n",
    "    V = V.T\n",
    "    ### TODO ###\n",
    "    return w, V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Sort the eigenvectors in descending order of the eigenvalues（固有ベクトルを固有値の降順に並べかえる）\n",
    "Input :\n",
    "1. Eigenvalues ( $K$個の固有値 ) : $\\boldsymbol{w}\\in\\mathbb{R}^{K}$\n",
    "1. Eigenvectors ( $K$個の固有値ベクトル ) : $\\boldsymbol{V}\\in\\mathbb{R}^{K\\times K}$\n",
    "\n",
    "Output : \n",
    "- Eigenvectors ( $K$個の固有値ベクトル ) : $\\boldsymbol{V}\\in\\mathbb{R}^{K\\times K}$ sorted in descending order of $\\boldsymbol{w}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Hint</summary>\n",
    "    <div><br>\n",
    "    - x.argsort() : Returns the indices that would sort an array in ascending order (昇順).\n",
    "    <br>\n",
    "    - x[::-1] : Returns reversed x.\n",
    "    </div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_matrix(w, V):\n",
    "    ### TODO ###\n",
    "    idx = w.argsort()[::-1]\n",
    "    V = V[idx]\n",
    "    ### TODO ### \n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "Please continue to debug until no error occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 1\n",
    "w = np.arange(4)\n",
    "V = np.arange(16).reshape(4, 4)\n",
    "V_sorted = sort_matrix(w, V)\n",
    "assert (V_sorted == np.flip(np.arange(16).reshape(4, 4), axis=0)).all()\n",
    "\n",
    "# test 2\n",
    "w = np.array([3,1,4,2])\n",
    "V = np.arange(16).reshape(4, 4)\n",
    "V_sorted = sort_matrix(w, V)\n",
    "assert (V_sorted == np.array([[8, 9, 10, 11],[0, 1, 2, 3],[12, 13, 14, 15],[4, 5, 6, 7]])).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Reduce dimensionality\n",
    "Input : \n",
    "1. Eigenvectors ( $K$個の固有値ベクトル ) : $\\boldsymbol{V}\\in\\mathbb{R}^{K\\times K}$ sorted by descending order of $\\boldsymbol{w}$\n",
    "1. Dimension of output (次元削減後の次元数) : $r\\in\\mathbb{R}^{1}$\n",
    "1. Average deviation matrix (平均偏差行列) : $\\boldsymbol{\\tilde{X}}\\in\\mathbb{R}^{N\\times K}$\n",
    "\n",
    "Output : \n",
    "- Output data reduced dimension : $\\boldsymbol{X\\_pca}\\in\\mathbb{R}^{N\\times r}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Hints</summary>\n",
    "    <div>\n",
    "    <br>\n",
    "    1. Fetch $r$-vectors from $\\boldsymbol{V}$ from the beginning : $\\boldsymbol{C}\\in\\mathbb{R}^{r\\times K}$\n",
    "    <br>\n",
    "    2. Caltulate $\\boldsymbol{X\\_pca}$ by calculate $\\boldsymbol{\\tilde{X}} \\times \\boldsymbol{C}^\\top$\n",
    "    </div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dimension(V_sorted, r, X_bar):\n",
    "    ### TODO ### \n",
    "    C = V_sorted[:r]\n",
    "    X_pca = np.dot(X_bar, C.T)\n",
    "    ### TODO ###\n",
    "    return X_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Create PCA function by merging above functions\n",
    "Input : \n",
    "1. Input data : $\\boldsymbol{X}=(\\boldsymbol{x_1},\\boldsymbol{x_2},\\cdots,\\boldsymbol{x_N})^\\top\\in\\mathbb{R}^{N\\times K}$ ( $N$ : number of data, $K$ : dimension of each data )\n",
    "1.  Dimension of output (次元削減後の次元数) : $r\\in\\mathbb{R}^{1}$\n",
    "\n",
    "Output : \n",
    "- Output data reduced dimension : $\\boldsymbol{X\\_pca}\\in\\mathbb{R}^{N\\times r}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_PCA(X, r):\n",
    "    \n",
    "    # 1. Calculate covariance matrix\n",
    "    X_bar, M = calc_converiance_matrix(X)\n",
    "\n",
    "    # 2. Solve the eigenvalue problem\n",
    "    w, V = solve_eigen_prob(M)\n",
    "\n",
    "    # 3. Sort the eigenvalues and eigenvectors in descending order of the eigenvalues\n",
    "    V_sorted = sort_matrix(w, V)\n",
    "\n",
    "    # 4. Reduce dimensionality\n",
    "    X_pca = reduce_dimension(V_sorted, r, X_bar)\n",
    "    \n",
    "    return X_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Try on iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "dataset = datasets.load_iris()\n",
    "\n",
    "features = dataset.data\n",
    "targets = dataset.target\n",
    "\n",
    "print ('Shape of features : ', features.shape)\n",
    "print ('Shape of targets : ', targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Use PCA function to reduce dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = calc_PCA(features, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Show the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, c in zip(np.unique(targets), ['r', 'g', 'b']):\n",
    "    plt.scatter(transformed[targets == label, 0], transformed[targets == label, 1], c=c, linewidths=0)\n",
    "plt.title('Principal component')\n",
    "plt.xlabel('pc1')\n",
    "plt.ylabel('pc2')\n",
    "plt.legend(dataset.target_names, loc='lower left', bbox_to_anchor=(1, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Introduce PCA by scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Import PCA module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Transform features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(features)\n",
    "transformed_sklearn = pca.transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Show the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, c in zip(np.unique(targets), ['r', 'g', 'b']):\n",
    "    plt.scatter(transformed_sklearn[targets == label, 0], transformed_sklearn[targets == label, 1], c=c, linewidths=0)\n",
    "plt.title('principal component')\n",
    "plt.xlabel('pc1')\n",
    "plt.ylabel('pc2')\n",
    "plt.legend(dataset.target_names, loc='lower left', bbox_to_anchor=(1, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
